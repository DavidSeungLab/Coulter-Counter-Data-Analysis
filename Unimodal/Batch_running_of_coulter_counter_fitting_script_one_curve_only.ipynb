{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting notebook to fit the browser size\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ec803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries and packages\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9551d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Running in batch mode\n",
    "#This needs a folder called data_inputs with csv files to use and a folder called output which it will put the fitting parameters and graphs of the fittings into\n",
    "\n",
    "parameters_from_fittings = [] #need to make an empty data frame with which I can add the fitting parameters to\n",
    "\n",
    "#empty lists which I will fill with sample names which have either worked or failed\n",
    "did_not_run = []\n",
    "failed_normal_fit_list = []\n",
    "successful_normal_fit_list = []\n",
    "failed_lognormal_fit_list = []\n",
    "successful_lognormal_fit_list = []\n",
    "\n",
    "\n",
    "\n",
    "#this is a for loop which reads input files in a directory called data_inputs and uses them as input for the coulter_counter_fit_rose_using_python_fitting script\n",
    "for filename in os.listdir('data_inputs/'): #runs with all files in the data_inputs folder\n",
    "\n",
    "    if filename.endswith(\".csv\") or filename.endswith(\".CSV\"): #will only work on csv files, so means you can have other file types in data_inputs and it should work fine    \n",
    "        file_name = filename #file_name is the variable which the run_coulter_count_fit_rose_using_python_fitting script uses as an input\n",
    "        try:\n",
    "            %run coulter_counter_fitting_script_one_curve_only.ipynb #this line runs the script\n",
    "        \n",
    "        except IndexError or RuntimeError:\n",
    "            did_not_run.append(filename)\n",
    "            \n",
    "        else: \n",
    "            parameters_from_fittings.append(fitting_parameters) #takes the fitting parameters from all the samples and stores together\n",
    "            #creating lists of samples which have been successful and those which have failed\n",
    "            successful_normal_fit_list.append(successful_normal)\n",
    "            failed_normal_fit_list.append(failed_normal)\n",
    "            successful_lognormal_fit_list.append(successful_lognormal)\n",
    "            failed_lognormal_fit_list.append(failed_lognormal)       \n",
    "    continue\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "        \n",
    "#concatenates the fitting parameters into an excel file\n",
    "#produces an output called 'Parameters_from_fittings.xlsx'\n",
    "parameters_from_fittings_data_frame = pd.DataFrame(parameters_from_fittings, columns=['Sample_name','Granule diameter normal fitting', 'Granule content normal fitting',  \n",
    "                                                                                      'Uncertainity for the normal fitting', 'Standard error of regression for the normal fitting',\n",
    "                                                                                      'Granule diameter lognormal fitting', 'Granule content lognormal fitting', \n",
    "                                                                                      'Uncertainity for the lognormal fitting', 'Standard error of regression for the lognormal fitting'])\n",
    "parameters_from_fittings_data_frame.to_excel(\"output/Parameters_from_fittings.xlsx\")\n",
    "\n",
    "\n",
    "#creating data frames with the fittings which were successful and those which failed\n",
    "successful_normal_fit_dataframe = pd.DataFrame(successful_normal_fit_list) \n",
    "failed_normal_fit_dataframe = pd.DataFrame(failed_normal_fit_list)\n",
    "successful_lognormal_fit_dataframe = pd.DataFrame(successful_lognormal_fit_list) \n",
    "failed_lognormal_fit_dataframe = pd.DataFrame(failed_lognormal_fit_list)\n",
    "\n",
    "#if loops which (if the dataframes are empty) fills it with either all successful or all failed as appropriate\n",
    "All_successful=\"All successful\"\n",
    "All_failed = \"All failed\"\n",
    "\n",
    "if failed_normal_fit_dataframe.empty:\n",
    "    failed_normal_fit_dataframe = pd.DataFrame(['All_successful'])\n",
    "\n",
    "if successful_normal_fit_dataframe.empty:\n",
    "    successful_normal_fit_dataframe = pd.DataFrame(['All_failed'])\n",
    "\n",
    "if failed_lognormal_fit_dataframe.empty:\n",
    "    failed_lognormal_fit_dataframe = pd.DataFrame(['All_successful'])\n",
    "\n",
    "if successful_lognormal_fit_dataframe.empty:\n",
    "    successful_lognormal_fit_dataframe = pd.DataFrame(['All_failed'])\n",
    "\n",
    "    \n",
    "#merging the data frames together and saving the results in excel\n",
    "#produces an output called 'Samples_which_fitted_successfully_and_samples_which_failed.xlsx'\n",
    "successful_and_failed_fittings = pd.concat([successful_normal_fit_dataframe[0], failed_normal_fit_dataframe[0], successful_lognormal_fit_dataframe[0], failed_lognormal_fit_dataframe[0]], axis=1)                \n",
    "successful_and_failed_fittings_results = successful_and_failed_fittings.set_axis([\"Successful samples for the normal fitting\", \"Failed samples for the normal fitting\", \"Successful samples for the lognormal fitting\", \"Failed samples for the lognormal fitting\"], axis='columns')\n",
    "successful_and_failed_fittings_results.to_excel(\"output/Samples_which_fitted_successfully_and_samples_which_failed.xlsx\")\n",
    "\n",
    "\n",
    "#creating a file of samples which failed - most likely during data import\n",
    "did_not_run_dataframe = pd.DataFrame(did_not_run, columns=[\"Samples where the script failed - most likely during data import, so check coulter_counter file\"])\n",
    "did_not_run_dataframe.to_excel(\"output/Samples_where_the_script_failed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa68da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
